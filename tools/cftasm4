#!/usr/bin/env python3
# coding: utf-8
# -*- python -*-
"""
The CFT Assembler, version 4
"""

import os
import io
import re
import sys
import copy
import types
import array
import pprint
import doctest
import argparse
import subprocess
import unicodedata

# Microcode 7 instruction set. This is the current one, with Memory Bank
# Registers and a Stack Pointer.
_BUILTINS = """;;; CFT Assembler Built-ins, Microcode Version 7.x.

;;; Native Instruction Mnemonics

.equ    IRET    &0000            ; 0000:0:0:000:-------  Interrupt Return
.equ    LRET    &0080            ; 0000:0:0:001:-------  Long Return
.equ    RET     &0100            ; 0000:0:0:010:-------  Return
.equ    TAS     &0180            ; 0000:0:0:011:-------  Transfer Accumulator to Stack Pointer
.equ    TSA     &0200            ; 0000:0:0:100:-------  Transfer Stack Pointer to Accumulator
.equ    TAD     &0280            ; 0000:0:0:101:-------  Transfer Accumulator to Data Register
.equ    TDA     &0300            ; 0000:0:0:110:-------  Transfer Data Register to Accumulator
.equ    ISR     &0400            ; 0000:0:1:000:LLLLLLL  Software Interrupt
.equ    PHA     &0480            ; 0000:0:1:001:-------  Push Accumulator
.equ    PPA     &0500            ; 0000:0:1:010:-------  Pop Accumulator
.equ    PHF     &0580            ; 0000:0:1:011:-------  Push Flags
.equ    PPF     &0600            ; 0000:0:1:100:-------  Pop Flags
.equ    STI     &0680            ; 0000:0:1:101:-------  Set Interrupt Flag
.equ    CLI     &0700            ; 0000:0:1:110:-------  Clear Interrupt Flag
.equ    WAIT    &0780            ; 0000:0:1:111:LLLLLLL  Wait for Interrupt
.equ    SHL     &0800            ; 0000:1:0:000:000LLLL  Bitwise Shift Left
.equ    SHR     &0810            ; 0000:1:0:000:001LLLL  Bitwise Shift Right
.equ    ASR     &0830            ; 0000:1:0:000:011LLLL  Arithmetic Shift Right
.equ    ROL     &0840            ; 0000:1:0:000:100LLLL  Roll Left
.equ    ROR     &0850            ; 0000:1:0:000:101LLLL  Roll Right
.equ    RLA     &0860            ; 0000:1:0:000:110LLLL  Roll Left Accumulator
.equ    RRA     &0870            ; 0000:1:0:000:111LLLL  Roll Right Accumulator

.equ    SKP     &0880            ; SKP bitmap instruction
.equ    NOP     SKP     #0000000 ; 0000:1:0:001:0000000  No Operation
.equ    SKIP    SKP     #0010000 ; 0000:1:0:001:--10000  Skip
.equ    SNP     SKP     #0001100 ; 0000:1:0:001:--011--  Skip on Non-Positive Accumulator
.equ    SPA     SKP     #0011100 ; 0000:1:0:001:--111--  Skip on Positive Accumulator
.equ    SNA     SKP     #0001000 ; 0000:1:0:001:--01---  Skip on Negative Accumulator
.equ    SZA     SKP     #0000100 ; 0000:1:0:001:--0-1--  Skip on Zero Accumulator
.equ    SSL     SKP     #0000010 ; 0000:1:0:001:--0--1-  Skip on Link
.equ    SSV     SKP     #0000001 ; 0000:1:0:001:--0---1  Skip on Overflow
.equ    SNN     SKP     #0011000 ; 0000:1:0:001:--11---  Skip on Non-Negative Accumulator
.equ    SNZ     SKP     #0010100 ; 0000:1:0:001:--1-1--  Skip on Non-Zero Accumulator
.equ    SCL     SKP     #0010010 ; 0000:1:0:001:--1--1-  Skip on Link Clear
.equ    SCV     SKP     #0010001 ; 0000:1:0:001:--1---1  Skip on Overflow

.equ    IND     &0b80            ; 0000:1:0:111:-------  Indirect
.equ    JPA     &0c00            ; 0000:1:1:000:-------  Jump to Accumulator
.equ    JSA     &0c80            ; 0000:1:1:001:-------  Jump to Subroutine at Accumulator
.equ    HCF     &0d80            ; 0000:1:1:011:-------  Halt and Catch Fire

; Note: the sub-instructions here can be used either with UOP (in which case
; the UOP mnemonic can be left out) or with either the IFL or IFV bitmap
; instructions. IFL and IFV must be specified.

.equ    UOP     &0e00            ; UOP bitmap instruction
.equ    IFL     &0e8c            ; IFL bitmap instruction
.equ    IFV     &0f0c            ; IFV bitmap instruction
.equ    NOP9    UOP     #0000000 ; 0000:1:1:100:0000000  No Operation, 9 Cycles
.equ    CLA     UOP     #0100000 ; 0000:1:1:100:-1-----  Clear Accumulator
.equ    CLL     UOP     #0010000 ; 0000:1:1:100:--1----  Clear Link
.equ    SEL     UOP     #0000001 ; 0000:1:1:100:--1---1  Set Link
.equ    NOT     UOP     #0001000 ; 0000:1:1:100:---1---  Complement Accumulator
.equ    NEG     UOP     #0001100 ; 0000:1:1:100:---11--  Negate Accumulator
.equ    INC     UOP     #0000100 ; 0000:1:1:100:----1--  Increment Accumulator
.equ    DEC     UOP     #0000010 ; 0000:1:1:100:-----1-  Decrement Accumulator
.equ    CPL     UOP     #0000001 ; 0000:1:1:100:------1  Complement Link

.equ    LIA     &1000            ; 0001:I:R:mmmmmmmmmm   Literal Address
.equ    LI      &1400            ; 0001:0:1:LLLLLLLLLL   Literal
.equ    LJSR    &1800            ; 0001:1:R:aaaaaaaaaa   Long Jump to Subroutine
.equ    LJMP    &2800            ; 0010:1:R:aaaaaaaaaa   Long Jump
.equ    JSR     &3000            ; 0011:I:R:mmmmmmmmmm   Jump to Subroutine
.equ    JMP     &4000            ; 0100:I:R:mmmmmmmmmm   Jump
.equ    IN      &5000            ; 0101:I:R:mmmmmmmmmm   Input from I/O Space
.equ    OUT     &6000            ; 0110:I:R:mmmmmmmmmm   Output to I/O Space
.equ    IOT     &7000            ; 0111:I:R:mmmmmmmmmm   I/O Transaction
.equ    LOAD    &8000            ; 1000:I:R:mmmmmmmmmm   Load Accumulator
.equ    STORE   &9000            ; 1001:I:R:mmmmmmmmmm   Store Accumulator
.equ    DSZ     &a000            ; 1010:I:R:mmmmmmmmmm   Decrement and Skip if Zero
.equ    ADD     &c000            ; 1100:I:R:mmmmmmmmmm   Add To Accumulator
.equ    AND     &d000            ; 1101:I:R:mmmmmmmmmm   Bitwise AND With Accumulator
.equ    OR      &e000            ; 1110:I:R:mmmmmmmmmm   Bitwise OR With Accumulator
.equ    XOR     &f000            ; 1111:I:R:mmmmmmmmmm   Bitwise XOR With Accumulator

;;; Instruction flags. These only make sense for instructions with I or R in
;;; their bitfields.

.equ    R       &0400            ; Zero Page ('register') reference
.equ    I       &0800            ; Indirection

;;; End of file.
"""


class UndefinedSymbolException(Exception):
    pass


class Symbol(object):
    """A member of the symbol table."""
    def __init__(self, filename, linenum, name, val=None, tokens=None):
        self.filename = filename
        self.linenum = linenum
        self.name = name
        self.val = val
        self.tokens = tokens


    def __str__(self):
        return '<%s %s = %04x>' % (self.__class__.__name__, self.name, self.val)


    def __repr__(self):
        if self.val is None:
            return '<Unresolved_{} {}={}>'.format(self.__class__.__name__, self.name, self.tokens)
        else:
            return '<{} {}={} ({})>'.format(self.__class__.__name__, self.name, self.val, self.tokens)


    @property
    def unresolved(self):
        return self.val is None


    # @property
    # def page(self):
    #     """Provide the middle 6 bits of the value."""
    #     return self.val & 0xfc00


    # @property
    # def offset(self):
    #     """Provide the lower 10 bits of the value."""
    #     return self.val & 0x03ff


    # @property
    # def assembly_val(self):
    #     """Provide a field for instruction assembly. For non-labels
    #     (i.e. instructions, EQUs, etc), we return the whole word."""
    #     return self.val


    # def inaccessible(self, addr):
    #     """Returns True if the value represents an address
    #     inaccessible from the current address due to them being on
    #     different pages.

    #     For non-label symbols, always return False. They don't
    #     necessarily represent addresses."""
    #     return False


class Label(Symbol):
    def __str__(self):
        return '<%s %s = %04x>' % (self.__class__.__name__, self.name, self.val)


    def __repr__(self):
        if self.val is None:
            return '<Unresolved_{} {}={}>'.format(self.__class__.__name__, self.name, self.tokens)
        else:
            return '<{} {}={} ({})>'.format(self.__class__.__name__, self.name, self.val, self.tokens)



class CFTAssembler(object):

    # The Assembler built-ins.
    BUILTINS = _BUILTINS

    # This protects against endless includes
    MAX_INCLUDE_LEVEL = 100

    # Lexer states
    TOK_SP = 0                  # Start of line, scanning for word
    TOK_WORD = 1                # Start of a word
    TOK_QUOTE = 2               # Tokenising a quoted string
    TOK_QUOTEESC = 3            # Escape '\' character in quoted string
    TOK_PAREN = 4               # Look for first argument in arg list
    TOK_PARENWORD = 5           # Parsing argument in arg list
    TOK_PARENSEP = 5            # Looking for comma or ')' in arg lits

    # Lexer types in token lists
    TKT_WORD = 0                # A bare word was found
    TKT_STR = 1                 # A double-quoted string
    TKT_LPAREN = 2              # Left parenthesis
    TKT_RPAREN = 3              # Right parenthesis
    TKT_PARENSEP = 3            # Comma in a parenthetic list

    # Lexer: escape character map
    ESCAPED_CHARS = {
        "a": '\a',
        "b": '\b',
        "t": '\t',
        "n": '\n',
        "v": '\v',
        "f": '\f',
        "r": '\r',
        "@": '\0',
        }

    # Valid Assembly directives
    DIRECTIVES = [
        '.bank',
        '.data',
        '.endmacro', '.end',
        '.endscope',
        '.endstring',
        '.equ',
        '.fill',
        '.include',
        '.longstring'
        '.macro',
        '.page',
        '.popns',
        '.pushns',
        '.reg',
        '.regfill',
        '.scope',
        '.str',
        '.strn',
        '.page',
        '.strp',
        '.word',
        ]

    # Binary bitfield character mapping
    BINDICT = {
        ":": "", ",": "", "'": "",
        "0": "0", "-": "0", "_": "0", ".": "0",
        "1": "1"
    }


    def __init__(self):
        # self.linenum = 1
        # self.out = sys.stderr.write

        # # The symbol table.
        self.symbols = dict()

        # The namespace stack.
        self.ns = list()

        # # The macro table and macro context stack
        self.macros = dict()

        # self.mcallno = 0

        # self.regexp_hex = re.compile('^(?:&|0x)([0-9A-Fa-f]+)$')
        # self.regexp_bin = re.compile('^#([0-9A-Fa-f]+)$')

        # # Filename and line numbers.
        # self.filename = '<none>'
        # self.linenum = 1

        # # The current address in memory.
        # self.minaddr = self.MEMSIZE
        # self.maxaddr = 0
        # self.boundwarn_low = False
        # self.boundwarn_high = False
        # self.setaddr(0)

        # # The memory image.
        # self.mem = array.array('H')
        # self.mem.fromlist([0x0000] * self.MEMSIZE)
        # self.sentinel = array.array('b')
        # self.sentinel.fromlist([32] * self.MEMSIZE)

        # self.opts, self.args = self.parseOpts()

        # # Create the processed assembly output file.
        # self.pasm = open(self.asm_file, 'w')

        # # State
        # self.wrap = False
        # self.jumped = False
        # self.bank = None
        
        # # Execute
        # try:
        #     self.run()
        # except IOError as e:
        #     self.die(str(e))


    def parse_command_line(self):
        """Parse command-line options."""
        p = argparse.ArgumentParser(description="An Assembler for the 2019 revision of the CFT.")

        p.add_argument('-o', '--out-file', metavar='OUTPUT-FILE', default='a.bin',
                     help='Output object file to OUTPUT-FILE (default: a.bin).')

        # p.add_option('-a', '--asm-file',
        #              help='Set processed assembly file output (default: OUTPUT-FILE.pasm).')
        # p.add_option('-m', '--map-file',
        #              help='Set map file output (default: OUTPUT-FILE.map).')
        p.add_argument('-s', '--symbol-file',
                       help='Set symbol file output (default: OUTPUT-FILE.sym).')
        # p.add_option('', '--xpm',
        #              help='Output an XPM file mapping the memory image. ' + 
        #              'This is merely a visualisation toy. (default: output nothing).')

        # p.add_option('', '--no-builtins', action='store_true',
        #              help='Start with no built-in symbols at all.')
        # p.add_option('-v', '--verbose', action='store_true',
        #              help='Print out assembled code')
        # p.add_option('', '--min-addr', action='store', type='int', default=0x0000,
        #              help='Set the starting address for dumping objects, verilog output ' + \
        #                  'et cetera (default: 0)')
        # p.add_option('', '--max-addr', action='store', type='int', default=0xffff,
        #              help='Set the ending address for dumping objects, verilog output ' + \
        #                  'et cetera (default: 65535)')
        # p.add_option('-B', '--banked', action='store_true',
        #              help='Assemble for extended 24-bit address space. All addresses are ' + \
        #                  'mod 8192, and you must use the .bank directive at least once.')
        # p.add_option('-B', '--banked', action='store_true',
        #              help='Assemble for extended 24-bit address space. All addresses are ' + \
        #                  'mod 8192, and you must use the .bank directive at least once.')

        p.add_argument('-I', '--include', metavar='DIRECTORY', action='append', default=['.'],
                       help="""Add to the include path. Can be specified multiple times to add multiple
                       search directories. Directories will be searched in the
                       order specified. The include path contains only the
                       current directory by default. Files in the current
                       directory will always take precedence.""")

        p.add_argument('--show-builtins', action='store_true',
                     help='Print out built-ins and exit without assembling anything.')

        p.add_argument('--debug-lexer', action='store_true',
                       help="""Debug the lexer by printing out its state of the lexer for every parsed
                       character. Extremely verbose.""")

        p.add_argument('--debug-preprocessor', action='store_true',
                       help="""Debug the preprocessor. This will print out includes and macro expansion info.""")

        p.add_argument('--debug-parser', action='store_true',
                       help="""Debug the parser by printing out every line in tokenised form. Extremely verbose.""")

        p.add_argument('--debug-macros', action='store_true',
                       help="""Debug macro definitions and use.""")

        p.add_argument('-D', '--debug', action='store_true',
                       help="""Raise full exception dumps on unexpected failures.""")

        p.add_argument(metavar="INPUT-FILE", dest="input_files",
                       nargs="*", help="Provide one or more files to assemble.")

        self.args = p.parse_args()


    def run(self):
        """Run the assembler."""

        # Parse the command line
        self.parse_command_line()

        # Set our various output filenames.
        base = os.path.splitext(self.args.out_file)[0]
        self.symbol_file = self.args.symbol_file or (base + '.sym')
        # self.map_file = self.args.map_file or (base + '.map')
        # self.asm_file = self.args.asm_file or (base + '.pasm')
        # self.xpm_map_file = self.args.xpm or (base + '.xpm')

        # Check mode of operation and act on it.
        if self.args.show_builtins:
            print(self.BUILTINS.strip())
            sys.exit(0)

        # # Sanity checking
        # if self.opts.min_addr > self.opts.max_addr:
        #     self.die('--min-addr must be less than or equal to --max-addr.')
        
        # For everything else, we need a filename to assemble.
        if not self.args:
            self.die('an input file must be provided.')

        # Run the assembler.
        self.parse()

        # # Output the object code.
        # self.outobj()


    ###############################################################################
    #
    # ERROR REPORTING
    #
    ###############################################################################


    def _msg(self, msg, filename=None, linenum=None):
        """Output a message, along with file and line number info."""
        sys.stderr.write('%s:%d: %s\n' % (filename or self.filename,
                                         linenum or self.linenum,
                                         msg))

    def warn(self, msg):
        """Output a warning message."""
        self._msg('warning: ' + msg)


    def error(self, msg):
        """Output an error message and fail."""
        # Is there a macro/file context we should print out?
        for (n, f, ln, mdef) in self.ctx:
            if mdef:
                self._msg("error: (in macro '%s' invocation)" % n,
                          filename=f, linenum=ln-1)
            else:
                self._msg("error: (included from %s on line %d)" % (f, ln),
                          filename=f, linenum=ln)

        self._msg('error: ' + msg)


    def fail(self, msg):
        """Output an error message and fail."""
        self.error(msg)
        sys.exit(1)


    def die(self, msg):
        """Output an interal, fatal error and fail."""
        sys.stderr.write('%s: %s\n' % (sys.argv[0], msg))
        sys.exit(1)


    ###############################################################################
    #
    # DEBUGGING
    #
    ###############################################################################

    def debug_lexer(self, s):
        if self.args.debug_lexer:
            print("{}:{}: [lexer] {}".format(self.filename, self.linenum, s))
            
    
    def debug_parser(self, s):
        if self.args.debug_parser:
            print("{}:{}: [parser] {}".format(self.filename, self.linenum, s))
            
    
    def debug_preprocessor(self, s):
        if self.args.debug_preprocessor:
            print("{}:{}: [preprocessor] {}".format(self.filename, self.linenum, s))
            
    
    def debug_macros(self, s):
        if self.args.debug_macros:
            print("{}:{}: [macros] {}".format(self.filename, self.linenum, s))

    ###############################################################################
    #
    # UTILITIES
    #
    ###############################################################################

    def get_nsname(self, symbol=None):
        if symbol is None and self.ns == []:
            return '.'
        elif symbol is None:
            return '.'.join(self.ns)
        return '.'.join(self.ns + [symbol])


    def is_word(self, token, word=None):
        """Return True if the specified token is a bare word. With an optional second
        argument, return True if it's the exact word specified."""
        return token[0] == self.TKT_WORD and ((word is None) or (token[1] == word))


    def is_label(self, token):
        """Return True if the specified token represents a label."""
        return token[0] == self.TKT_WORD and token[1][-1] == ':'


    def check_valid_directive(self, token):
        """Ensure a token represents a valid dot directive. Report a fatal parse error
        otherwise. Allow either a string or a token tuple to be provided."""
        if type(token) == tuple:
            token = token[1]
        if token not in self.DIRECTIVES:
            self.fail("Unknown directive {}.".format(token))


    def get_symbol(self, sym):
        """Return the value of a symbol from the symbol table. Return None if it
        couldn't be found.
        """
        # # if the symbol has a '.' in it, it should fully qualified. Look for it first.
        # if '.' in sym:
        #     return self.symbols.get(sym)

        # # Maybe it's a global symbol with no '.'.
        # if sym in self.symbols:
        #     return self.symbols[sym]

        for x in range(len(self.ns), -1, -1):
            try:
                nssym = '.'.join(self.ns[0:x] + [sym])
                #print "Pass", self.passnum, ", Looking up", nssym, self.ns
                return self.symbols[nssym]
            except KeyError:
                continue
        return None


    def pushParseContext(self, macro, filename, linenum, mdef):
        """Push a macro context onto the context stack. This is used for reporting the
        exact location of file inclusions and macro expansions.

        This is used for error reporting.

        """
        self.ctx.append((macro, filename, linenum, mdef))


    def popParseContext(self):
        """Pop a macro context from the context stack.

        This is used for error reporting."""
        try:
            return self.ctx.pop()
        except IndexError:
            self.die('Attempted pop from empty context stack.')


    def set_addr(self, a):
        """Set the assembly address."""
        self.addr = a & self.addr_mask
        self.jumped = True
        self.wrap = False


    def inc_addr(self, by=1):
        """Increment the address."""
        # If the address has just been set and no data has been written to
        # memory, don't increment yet.
        if self.jumped:
            return

        self.addr = (self.addr + by) & self.addr_mask
        if self.addr == 0:
            self.wrap = True
        elif self.wrap and self.addr == 1:
            # Warn the second time this gets here to avoid a spurious
            # warning when 0xffff is written to (and no further).
            self.wrap = False
            self.warn('64KW bank boundary crossed.')


    
            
    
    ###############################################################################
    #
    # THE TOKENISER
    #
    ###############################################################################

    def tokeniser(self, filename):
        if filename == '<builtins>':
            f = self.BUILTINS.split('\n')
        else:
            try:
                f = open(filename, 'rt')
            except Exception as e:
                self.die("Unable to open {}: {}".format(filename, e))

        fmt = lambda x: x.replace('{', '\033[1m{').replace('}', '}\033[0m')

        # Set the parse context.
        self.filename = filename
        self.debug_lexer(fmt("\n--- START FILENAME: {}'").format(filename))

        for i, line in enumerate(f, 1):
            (self.linenum, self.line) = (i, line)
            line = line.strip()
            tokens = []
            tmptoken = ''
            state = self.TOK_SP
            self.debug_lexer(fmt("\n+++ LINE: '{}'").format(line))
            for c in line.rstrip('\n'):
                self.debug_lexer(fmt("*** c='{c}', state={state}, tmptoken={tmptoken}, tokens={tokens}").format(**locals()))

                # The state machine (warning: sprawling code!)
                if state == self.TOK_SP:
                    # Ignore white space, look for the beginning of a word
                    if c in "\t\r\n ":
                        continue
                    elif c in ";/":
                        # Comment. Ignore rest of line.
                        break
                    elif c == '"':
                        state = self.TOK_QUOTE
                        tmptoken = ''
                    elif c == '(':
                        tokens.append((self.TKT_LPAREN, '('))
                        state = self.TOK_PAREN
                    elif c == ':':
                        self.fail("Parse error. If this is label, delete white spaec before the colon.")
                    else:
                        state = self.TOK_WORD
                        tmptoken = c

                elif state == self.TOK_QUOTE:
                    # Read until a closing double quote is found
                    if c == '\\':
                        state = self.TOK_QUOTEESC
                        continue
                    elif c == '"':
                        state = self.TOK_SP
                        tokens.append((self.TKT_STR, tmptoken))
                    else:
                        tmptoken += c

                elif state == self.TOK_QUOTEESC:
                    # An escape character has been seen in a string. Some
                    # characters (e.g \n) are treated specially. All others are
                    # inserted into the string as-is.
                    tmptoken += self.ESCAPED_CHARS.get(c, c)
                    state = self.TOK_QUOTE

                elif state == self.TOK_WORD:
                    # Add letters to a word until we meet whitespace
                    if c in "\t\r\n ":
                        tokens.append((self.TKT_WORD, tmptoken))
                        state = self.TOK_SP
                    elif c == '(':
                        if tmptoken:
                            tokens.append((self.TKT_WORD, tmptoken))
                            tmptoken = ''
                        tokens.append((self.TKT_LPAREN, '('))
                        state = self.TOK_PAREN
                    else:
                        # We'll allow any character here.
                        tmptoken += c

                elif state == self.TOK_PAREN:
                    # We just start an arg list.
                    if c in "\t\r\n ":
                        continue
                    elif c in ')':
                        # End of arg list
                        tokens.append((self.TKT_RPAREN, ')'))
                        state = self.TOK_SP
                    elif c == ',':
                        self.fail("Unexpected comma in parameter list.")
                    else:
                        state = self.TOK_PARENWORD
                        tmptoken = c

                elif state == self.TOK_PARENWORD:
                    # im in ur parens lists parsing ur words
                    if c in "\t\r\n ":
                        if tmptoken:
                            tokens.append((self.TKT_WORD, tmptoken))
                    elif c == ',':
                        if not tmptoken:
                            self.fail("Unexpected closing parenthesis.")
                        tokens.append((self.TKT_WORD, tmptoken))
                        state = self.TOK_PAREN
                    elif c == ')':
                        if not tmptoken:
                            self.fail("Unexpected closing parenthesis.")
                        tokens.append((self.TKT_WORD, tmptoken))
                        tokens.append((self.TKT_RPAREN, ')'))
                        state = self.TOK_SP
                    else:
                        # We'll allow any character here.
                        tmptoken += c

            # Finish lexing the last parsed word, if there is one.
            if state == self.TOK_WORD and tmptoken:
                tokens.append((self.TKT_WORD, tmptoken))

            # End of line. Perform sanity checks.
            if state == self.TOK_QUOTEESC:
                self.fail("Missing closing double quote.")
            elif state == self.TOK_QUOTE:
                self.fail("Line ended in backspace. Were you escaping something?")
            elif state != self.TOK_SP and state != self.TOK_WORD:
                self.fail("Parse error.")

            # Done.
            if tokens:
                yield(tokens)

            # Next line.
        self.debug_lexer(fmt("\n--- END FILENAME: {}'").format(filename))


    ###############################################################################
    #
    # THE PREPROCESSOR
    #
    ###############################################################################

    def preprocessor(self, filename):
        """A very basic preprocessor: just handle file inclusions."""
        for tokens in self.tokeniser(filename):
            #self.debug_parser("tokens: {}".format(tokens))
            
            # Is this an include directive?
            if tokens[0] == (self.TKT_WORD, '.include'):
                for tokens in self.preprocessor_dot_include(tokens):
                    yield tokens
            else:
                yield tokens


    def preprocessor_dot_include(self, tokens):
        """Include an .asm file."""

        if self.include_level >= self.MAX_INCLUDE_LEVEL:
            self.fail("Too many include levels.")
        self.include_level += 1

        try:
            include, include_fname = tokens
            assert include[0] == self.TKT_WORD # Sanity check; this has been checked already
            assert include_fname[0] == self.TKT_STR

        except:
            self.fail("Error parsing .include directive.")

        # Look for the file in the specified include path
        fname = include_fname[1]
        class FoundFile(Exception):
            pass

        try:
            for pathcomp in self.args.include:
                fname = os.path.join(pathcomp, include_fname[1])
                if os.path.exists(fname):
                    raise FoundFile
            self.fail("File {} not found in include path {}".format(
                include_fname[1], ':'.join(self.args.include)))
        except FoundFile:
            pass

        # Get a parse state and return it to the preprocessor
        self.debug_preprocessor("include file {} ({})".format(include_fname[1], fname))
        savedState = self.filename, self.linenum # Why is this necessary?
        self.pushParseContext(fname, self.filename, self.linenum, None)

        # Note: mutual recursion!
        for tokens in self.preprocessor(fname):
            yield tokens

        # Done, pop the parse context
        self.popParseContext()
        self.filename, self.linenum = savedState
        self.debug_preprocessor("end of included file {}".format(fname))
        self.include_level -= 1


    ###############################################################################
    #
    # PARSING TOKENS INTO VALUES
    #
    ###############################################################################

    def parse_literal(self, literal):
        """Parse an integer literal.
    
        Base Conventions and sigils:
    
        * default base: 10 (e.g. 64, 0001). No sigil for this one.
        * base 16: "&" sigil. E.g. &20 == 32
        * base 2: "#. E.g. #10:1100_ = 88. Ony of "0-._" are parsed as '0'. '1'
          is parsed as 1. ":,'" are ignored entirely. Useful for building
          human-readable bitfields.

        >>> x = CFTAssembler()
        >>> x.parse_literal('&10')
        16
        >>> x.parse_literal('&fffe')
        65534
        >>> x.parse_literal('16')
        16
        >>> x.parse_literal('#10000')
        16
        >>> x.parse_literal('#1____')
        16
        >>> x.parse_literal('#1....')
        16
        >>> x.parse_literal('#1----')
        16
        >>> x.parse_literal('#1--:--')
        16
        >>> x.parse_literal('foobar')
        Traceback (most recent call last):
        ValueError: unable to parse literal 'foobar'

        """
        if literal.startswith('#'):
            try:
                newlit = ''.join(self.BINDICT[x] for x in literal[1:])
                newint = int(newlit, 2)
            except:
                self.fail("Unable to parse binary literal '{}'".format(literal))
            #print("lit={}, conv={}".format(newlit, newint))
            return int(newlit, 2)

        elif literal.startswith('&'):
            try:
                return int(literal[1:], 16)
            except:
                self.fail("Unable to parse hexadecimal literal '{}'".format(literal))

        elif literal.startswith('0x'):
            try:
                return int(literal[2:], 16)
            except:
                self.fail("Unable to parse hexadecimal literal '{}'".format(literal))

        elif literal[0] in "0123456789":
            try:
                return int(literal)
            except:
                self.fail("Unable to parse decimal literal '{}'".format(literal))

        return None
        

    def parse_fields(self, tokens):
        for tkt, token in tokens:
            parsed_literal = self.parse_literal(token)
            if parsed_literal is not None:
                yield parsed_literal
            else:
                # Do we have a resolved symbol in the symbol table?
                sym = self.get_symbol(token)
                if sym is not None and sym.val is not None:
                    yield sym.val
                else:
                    # self.warn("Unresolved symbol {} in .equ".format(token))
                    yield token
        

    ###############################################################################
    #
    # THE PARSER
    #
    ###############################################################################


    def prepare_for_parse(self):
        """Initialise parse state."""
        # Clear our parse state
        self.ns = []              # The namespace stack
        self.scope = 0            # The scope number counter
        self.scopedepth = 0       # Scope depth (for sanity checking)
        self.longstring = None    # This holds long strings
        self.compstring = None    # This holds compressed strings
        self.jumped = False       # The address has changed, don't increment.
        self.addr_mask = 0xffffff # Set a 24-bit mask
        self.set_addr(0)


    def parse_dot_pushns(self, tokens):
        if len(tokens) != 2:
            self.fail("incorrect use of .pushns")
        elif not self.is_word(tokens[1]):
            self.fail("expected namespace identifier after .pushns")
        elif tokens[1][1][0] == '_':
            self.fail("namespace names may not start with _")
        else:
            self.ns.append(tokens[1][1])
            self.debug_macros("Namespace set to {}".format(self.get_nsname()))


    def parse_dot_popns(self, tokens):
        if not self.ns:
            self.fail(".popns seen before .pushns")
        elif len(tokens) == 1:
            self.warn("missing namespace to pop, assuming {}. (this will be an error soon)".format(self.ns[-1]))
            self.ns.pop(-1)
            self.debug_macros("Namespace popped back to {}".format(self.get_nsname()))
        elif not self.is_word(tokens[1]):
            self.fail("expected namespace identifier after .popns")
        elif tokens[1][1][0] == '_':
            self.fail("namespace names may not start with _")
        elif self.ns[-1].startswith("_s"):
            self.fail("missing .endscope before .popns")
        elif tokens[1][1] != self.ns[-1]:
            self.fail(".popns {} seen but last namespace pushed was {}".format(tokens[1][1], self.ns[-1]))
        else:
            self.ns.pop(-1)
            self.debug_macros("Namespace popped back to {}".format(self.get_nsname()))


    def parse_dot_scope(self, tokens):
        if len(tokens) != 1:
            self.fail("error parsing .scope, no arguments expected")
        else:
            self.scope += 1
            self.scopedepth += 1
            self.ns.append("_s" + str(self.scope))
            self.debug_parser(".scope {}, depth {}".format(self.scope, self.scopedepth))


    def parse_dot_endscope(self, tokens):
        if not self.ns:
                self.fail(".endscope seen before .scope")
        elif len(tokens) != 1:
            self.fail("error parsing .endscope, no arguments expected")
        else:
            if not self.ns[-1].startswith("_s"):
                self.fail(".endscope seen before .scope (depth={})".format(self.scopedepth))
            self.ns.pop(-1)
            self.scopedepth -= 1
            if (self.scopedepth < 0):
                self.fail("internal error, scope level is negative")
        self.debug_parser(".endscope {}, depth {}, ns={}".format(self.scope, self.scopedepth, self.ns))


    def parse_dot_equ(self, tokens):
        if len(tokens) < 3:
            self.fail("error parsing .equ, expecting at least two arguments.")
        if not all(self.is_word(x) for x in tokens[1:]):
            self.fail("error parsing .equ, expecting bareword.")

        sym, definition = tokens[1][1], list(x[1] for x in tokens[2:])
        nssym = self.get_nsname(sym)

        parsed = list(self.parse_fields(tokens[2:]))

        # Has this symbol been resolved fully at this time?
        if all(type(x) == int for x in parsed):
            value = parsed[0]
            for x in parsed[1:]:
                value = value | x
            self.symbols[nssym] = Symbol(self.filename, self.linenum, nssym, val=value, tokens=" ".join(definition))
        else:
            self.symbols[nssym] = Symbol(self.filename, self.linenum, nssym, tokens=parsed)
        self.debug_parser(".equ seen: sym={}, nssym={}, def={}, parsed={}".format(sym, nssym, definition, parsed))


    def parse_dot_macro(self, tokens, macro_def):
        self.debug_macros(tokens)
        # Check it
        if macro_def is not None:
            self.fail("nested .macro definition. Probably a missing .endmacro.")
        elif tokens[1][0] != self.TKT_WORD:
            self.fail("Expected macro name")
        elif tokens[2] != (self.TKT_LPAREN, '('):
            self.fail("Expected macro definition argument list")
        elif tokens[-1] != (self.TKT_RPAREN, ')'):
            self.fail("Parse error reading macro definition: garbage after argument list")
        else:
            # Ensure all the args are the right type.
            for arg in tokens[3:-2]:
                if arg[0] != self.TKT_WORD:
                    self.fail("Parse error reading macro argument '{}'. Word expected.".format(arg[1]))
        macro_def = ''
        macro_start = self.linenum
        macro_name = tokens[1][1]
        macro_args = list(x[1] for x in tokens[3:-2])
        self.debug_macros("macro name={}, args={}".format(macro_name, macro_args))
        return macro_name, macro_args, macro_start, macro_def


    def parse_dot_endmacro(self, tokens, macro_name, macro_args, macro_start, macro_def):
        if macro_def is None:
            self.fail(".endmacro seen before .macro")
        self.debug_macros(".endmacro seen")
        self.macros[self.get_nsname(macro_name)] = (self.filename, macro_start, macro_args, macro_def)

    
    def pass_macro_discovery(self):
        self.dots = dict()
        self.prepare_for_parse()
        self.expand_macros = False # Don't expand any macros for this passduring this pass
        macro_def = None
        for filename in ['<builtins>'] + self.args.input_files:
            for tokens in self.preprocessor(filename):
                #self.debug_parser(tokens)

                # Parse namespaces. We need those to qualify any macro names we
                # encounter.
                if self.is_word(tokens[0], ".pushns"):
                    self.parse_dot_pushns(tokens)

                elif self.is_word(tokens[0], ".popns"):
                    self.parse_dot_popns(tokens)

                elif self.is_word(tokens[0], ".scope"):
                    self.parse_dot_scope(tokens)
                    self.debug_parser("scope now {}".format(self.ns[-1]))

                elif self.is_word(tokens[0], ".endscope"):
                    self.debug_parser("endscope {}".format(self.ns[-1]))
                    self.parse_dot_endscope(tokens)

                # Opportunistically parse .equs too, while we're at it
                elif self.is_word(tokens[0], ".equ"):
                    self.parse_dot_equ(tokens)

                # Parse a macro definition
                elif tokens[0] == (self.TKT_WORD, ".macro"):
                    macro_name, macro_args, macro_start, macro_def = self.parse_dot_macro(tokens, macro_def)

                elif tokens[0] in [ (self.TKT_WORD, '.end'), (self.TKT_WORD, '.endmacro') ]:
                    if tokens[0][1] == '.end':
                        self.warn(".end is deprecated. Change to .endmacro.")
                    self.parse_dot_endmacro(tokens, macro_name, macro_args, macro_start, macro_def)
                    macro_def = None

                elif macro_def is not None:
                    # Append another line to the macro definition.
                    macro_def += self.line

                elif tokens[0][1] == '.':
                    # But report unknown directives
                    self.check_valid_directive(tokens[0])

            # Sanity checks at end of file.
            if macro_def is not None:
                self.fail("File ended before .endmacro was seen.")
            if self.ns and self.ns[-1].startswith("_ns"):
                self.fail("File ended before .endscope was seen.")


    def pass_symbols_and_label_resolution(self):
        self.dots = dict()
        self.prepare_for_parse()
        self.expand_macros = True

        macro_def = None
        for filename in ['<builtins>'] + self.args.input_files:
            for tokens in self.preprocessor(filename):
                #self.debug_parser(tokens)

                # Parse namespaces. We need those to qualify any macro names we
                # encounter.
                if self.is_word(tokens[0], ".pushns"):
                    self.parse_dot_pushns(tokens)

                elif self.is_word(tokens[0], ".popns"):
                    self.parse_dot_popns(tokens)

                elif self.is_word(tokens[0], ".scope"):
                    self.parse_dot_scope(tokens)
                    self.debug_parser("scope now {}".format(self.ns[-1]))

                elif self.is_word(tokens[0], ".endscope"):
                    self.debug_parser("endscope {}".format(self.ns[-1]))
                    self.parse_dot_endscope(tokens)

                # Opportunistically parse .equs too, while we're at it
                elif self.is_word(tokens[0], ".equ"):
                    self.parse_dot_equ(tokens)

                # Parse a macro definition
                elif tokens[0] == (self.TKT_WORD, ".macro"):
                    # .macro was parsed and verified on the previous pass. Just
                    # update our state here.
                    macro_def = True

                elif tokens[0] in [ (self.TKT_WORD, '.end'), (self.TKT_WORD, '.endmacro') ]:
                    # .endmacro was parsed and verified on the previous
                    # pass. Just update our state here.
                    macro_def = None

                elif macro_def is not None:
                    # Ignore macro definitions here.
                    continue

                elif tokens[0][1] == '.':
                    # But report unknown directives
                    self.check_valid_directive(tokens[0])

                else:
                    self.assemble(tokens, dryrun=True)

            # Sanity checks at end of file.
            pass


    def parse(self):
        """Assemble the input files."""

        self.ctx = list()
        self.filename = '<none>'
        self.linenum = -1
        self.include_level = 0

        # This is a three-pass assembler.
        self.pass_macro_discovery()
        self.pass_symbols_and_label_resolution()
        #self.pass_assembly()

        #pprint.pprint(self.macros, width=200)
        #pprint.pprint(self.symbols, width=200)
        # self.pass_symbol_discovery()
        # self.pass_assembly()

        print(self.dots.keys())
        
        # Sanity checks
        self.sanity_checks()

        # Output stuff
        self.write_symbol_table()

            # # First, parse the builtins.
            # self.filename = '<builtins>'
            # self.linenum = 0
            # self.assembly_pass(self.BUILTINS.split('\n'))

            # # Then, parse each input file in order.
            # for filename in self.args:
            #     self.filename = filename
            #     self.linenum = 0
            #     self.mcallno = 0

            #     self.assembly_pass(open(filename))

            # # Warn about unbalanced namespaces
            # if len(self.ns):
            #     self.warn("Namespace stack not empty at end of document (%s)" %
            #               (', '.join(self.ns)))

            # if self.deferred:
            #     print("Deferred symbols:", self.deferred)
            #     # Undefine any deferred symbols
            #     for sym in self.deferred:
            #         print("deleting", sym)
            #         try:
            #             del self.symbols[sym]
            #         except KeyError:
            #             continue
                

            # # Move on to the next pass. There can be multiple symbol discovery
            # # passes, depending on whether there are deferred symbols (forward
            # # definitions that couldn't be resolved in one pass).
            # if self.passnum == self.PSN_MACRO_DISCOVERY:
            #     self.passnum = self.PSN_SYMBOL_DISCOVERY
            # elif self.passnum == self.PSN_SYMBOL_DISCOVERY:
            #     if not self.deferred:
            #         self.passnum = self.PSN_ASSEMBLY
            #     else:
            #         print("Deferred symbols:", self.deferred)
            # elif self.passnum == self.PSN_ASSEMBLY:
            #     # At the end of the last parse, print out the symbol table.
            #     self.outmap()
            #     self.outsym()
            #     self.outxpm()
            #     break


    def parse_label(self, token):
        """Parse a label or address definition."""

        # Try to parse the specification. Use parse_fields
        name = token[1][:-1]
        tokenlist = [[ self.TKT_WORD, name ]]
        n = list(self.parse_fields(tokenlist))

        # If we did everything right, we should have a singleton list with
        # either an integer address or a string.
        assert len(n) == 1

        # If a number was specified, n[0] will be an integer and this will
        # work.
        if type(n[0]) == int:
            self.set_addr(n[0])
            self.debug_parser("Address &{:04x}".format(self.addr))
        else:
            nssym = self.get_nsname(name)
            self.symbols[nssym] = Label(self.filename, self.linenum,
                                        nssym, val=self.addr)
            self.debug_parser("Label {} ({})".format(name, nssym))


    def assemble(self, tokens, dryrun=False):
        """Assemble a line."""
        # The first token could be label
        if self.is_label(tokens[0]):
            self.parse_label(tokens[0])
            tokens = tokens[1:]

        if not tokens:
            return
        self.debug_parser("Assemble: {}".format(tokens))


    ###############################################################################
    #
    # SANITY CHECKING THE PARSED ASSEMBLY
    #
    ###############################################################################

    def sanity_checks(self):
        unresolved_symbols = [ x for x in self.symbols.values() if x.unresolved ]
        if unresolved_symbols:
            tmp_filename, tmp_linenum = self.filename, self.linenum
            for sym in unresolved_symbols:
                self.filename, self.linenum = sym.filename, sym.linenum
                self.error("Unresolved symbol: {} ({} undefined)".format(
                    sym.name,
                    ', '.join(x for x in sym.tokens if type(x) == str )))
            sys.exit(1)


    ###############################################################################
    #
    # OUTPUT FUNCTIONALITY
    #
    ###############################################################################

    def write_symbol_table(self):
        """Print out the symbol table."""
        # Open the symbol output file.
        try:
            with open(self.symbol_file, 'wt') as out:

                maxnamelength = max(len(x) for x in list(self.symbols.keys()))

                # TODO: make this more Python-3
                fmt = "%%-%ds  %%04x  %%-6s  %%s:%%d\n" % maxnamelength
                hdr = "%%-%ds  %%-4s  %%-6s  %%s\n" % maxnamelength
                header = hdr % ('Name', 'Val', 'Type', 'Defined in')

                out.write(header + ('-' * 79) + '\n')
                for sym in sorted(list(self.symbols.values()), key=lambda x: (x.filename, x.linenum)):
                    out.write(fmt % (sym.name, sym.val,
                                     sym.__class__.__name__.lower(),
                                     sym.filename, sym.linenum or '?'))

        except Exception as e:
            if self.args.debug:
                raise
            self.die("Whoops, failed to write symbol table: {}".format(e))
            
            

    


    ###############################################################################
    ###############################################################################
    ###############################################################################
    ###############################################################################


    def assembly_pass(self, stuff):
        """Perform a single pass of the assembler."""
    
        for line in stuff:
            orgline = line.rstrip().expandtabs()
            self.linenum += 1

            line = line.strip()

            # Strip blank lines.
            if not line:
                continue

            tokens = list(self.lexer(line))
            if self.opts.debugging:
                print("D: %s:%d: %04x %s" % (self.filename, self.linenum, self.addr,
                                         ', '.join('<%s>' % x for x in tokens)))

            # Hm, the line is all comments and white space.
            if not tokens:
                continue

            # Process address-less directives
            if tokens[0].startswith('.'):
                if tokens[0] == '.equ':
                    if len(tokens) < 2:
                        self.fail('Value expected after .equ')
                    # Allow forward definitions: don't parse the token unless it's the last pass.
                    # TODO: Verify this code and remove 'True or'.
                    val = self.parseField(tokens[2:], allbits=True)
                    # if self.passnum == self.PSN_ASSEMBLY:
                    #     val = self.parseField(tokens[2:], allbits=True)
                    #     #print self.passnum, tokens[1], hex(val)
                    # else:
                    #     print self.parseField(tokens[2:], allbits=True)
                    #     val = 0xbeef
                    #     print self.passnum, tokens[1], hex(val)
                    self.addSymbol(tokens[1], val)
                    continue
                elif tokens[0] == '.macro':
                    self.parseMacroDef(line, stuff)
                    continue
                elif tokens[0] == '.include':
                    self.includeFile(line)
                    continue
                elif tokens[0] == '.pushns':
                    self.pushNamespace(line)
                    continue
                elif tokens[0] == '.popns':
                    self.popNamespace(line)
                    continue
                elif tokens[0] == '.scope':
                    self.startScope(line)
                    continue
                elif tokens[0] == '.endscope':
                    self.endScope(line)
                    continue

            # Is there a label or address?
            if len(tokens) > 1 and tokens[1] == ':':
                label = tokens[0]
                try:
                    self.setaddr(self.parseInt(label))
                    tokens = tokens[2:]
                except ValueError:
                    # It's a label.
                    self.addSymbol(tokens[0], self.addr, symtype=Label)
                    tokens = tokens[2:]

            # We purposefully don't _continue_ after a successful label parse.
            # There may be an instruction on the same line as the label.


            # Is this a macro call? If so, it should be the only thing on a
            # line, and be invoked like macro() or macro(a,b,c,...).
            x = re.findall('^\s*([\w.]+)\s*\((.+)\)\s*$', ' '.join(tokens))
            if x:
                #print "assemble macro", x[0]
                self.assembleMacro(x[0])
                continue

            # It must be an instruction, then. Only assemble after the symbol
            # discovery pass, otherwise some labels won't be defined.
            if tokens:

                # Is this an address-ful directive?
                if tokens[0].startswith('.'):
                    self.assembleDataDirective(tokens, orgline)
                else:
                    self.assembleInstruction(tokens, orgline)

                # The address increases regardless of the pass number.
                #sys.stderr.write('+++INC+++\n')
                self.incaddr()


    def parseMacroDef(self, line, stuff):
        """Parse a macro definition."""
        
        start = self.linenum

        # Parse the macro definition
        try:
            name, arglist = re.findall('^\.macro\s+(\w+)\s*\((.*?)\)\s*', line)[0]
            arglist = re.split('\s*,\s*', arglist)

        except (TypeError, IndexError):
            self.fail('syntax error parsing macro definition')

        macrodef = []
        for line in stuff:
            orgline = line.rstrip().expandtabs()
            self.linenum += 1

            if line.strip() == '.end':
                if self.passnum == self.PSN_MACRO_DISCOVERY:
                    try:
                        pf, pl = self.getMacro(name)[:2]
                        self.fail("macro '%s' previously defined in %s, line %d." % (name, pf, pl))
                    except KeyError:
                        # New macro. Store it.
                        nsname = '.'.join(self.ns + [name])
                        self.macros[nsname] = (self.filename, start, arglist, macrodef)
                        #print "Defined macro", nsname
                return
            macrodef.append(line)

        self.fail("Macro without .end (started on line %d)" % start)


    def pushParseContext(self, macro, filename, linenum, mdef):
        """Push a macro context onto the context stack.

        This is used for error reporting."""
        self.ctx.append((macro, filename, linenum, mdef))


    def popParseContext(self):
        """Pop a macro context from the context stack.

        This is used for error reporting."""
        try:
            return self.ctx.pop()
        except IndexError:
            self.die('Attempted pop from empty context stack.')


    def assembleMacro(self, match):
        """Assemble a macro call.

        Macro calls are assembled in all passes by temporarily reading input
        from the macro definition, not the current file.
        """
        name, arglist = match
        arglist = [x.strip() for x in re.split('\s*,\s*', arglist)]

        try:
            #print "Assembling macro", name
            mf, mln, mal, mdef = self.getMacro(name)
        except KeyError:
            self.fail("undefined macro '%s'" % name)

        if len(arglist) != len(mal):
            self.fail("macro '%s' expects exactly %d arguments" % (name, len(mal)))

        # Copy the macro definition, because we'll be making changes
        mdef_inst = copy.copy(mdef)

        # Add a unique serial number argument. Useful for namespacing labels.
        self.mcallno += 1
        for i, line in enumerate(mdef_inst):
            mdef_inst[i] = line.replace('%_', str(self.mcallno))

        # Replace placeholders with actual arguments
        for argname, argval in zip(mal, arglist):
            for i, line in enumerate(mdef_inst):
                # WARNING: this will mess up with args like %n and
                # %num.
                #mdef_inst[i] = line.replace('%' + argname, argval)
                mdef_inst[i] = re.sub(r'%{?' + argname + r'(}|\b)', argval, line)

        # Set us up to parse the macro definition.
        if self.opts.debugging:
            sys.stderr.write('D: %s:%d: execute macro %s, arglist: %s\n' % \
                                 (self.filename, self.linenum, name, ', '.join(arglist)))
        fn, nl = self.filename, self.linenum
        self.pushParseContext(name, self.filename, self.linenum, self.getMacro(name))
        self.filename = mf
        self.linenum = mln
        self.assembly_pass(mdef_inst)
        self.popParseContext()
        self.filename, self.linenum = fn, nl
        if self.opts.debugging:
            sys.stderr.write('D: %s:%d: end of macro %s, arglist: %s\n' % \
                                 (self.filename, self.linenum, name, ', '.join(arglist)))


    def assembleDataDirective(self, tokens, orgline):
        """Assemble a data directive.
        
        A data directive is anything that starts with a . (e.g. .word, .str)
        and includes data for the output file (as opposed to other directives,
        which modify the behaviour of the assembler.
        """
        if tokens[0] == '.word':
            self.jumped = False
            if self.passnum == self.PSN_ASSEMBLY:
                val = self.parseField(tokens[1:], allbits=True, pageboundary=False)
                self.poke(val, poketype='W')
                self.logasm(val, orgline=orgline)

        elif tokens[0] == '.reg':
            if len(tokens) < 2:
                self.fail('Value expected after .reg')
            # Allow forward definitions: don't parse the token unless it's the last pass.
            # TODO: Verify this code and remove 'True or'.
            if self.passnum == self.PSN_ASSEMBLY:
                val = self.parseField(tokens[2:], allbits=True)
                #print self.passnum, tokens[1], hex(val)
            else:
                val = 0xdead
                #print self.passnum, tokens[1], hex(val)
            self.addSymbol('$' + tokens[1], self.addr, symtype=Register)
            self.addSymbol(tokens[1], val)

            self.poke(0x0000, poketype='R')
            if self.passnum == self.PSN_ASSEMBLY:
                self.logasm(val, orgline=orgline)
        elif tokens[0] in ('.str', '.data'):
            self.assembleString(tokens, orgline)
        elif tokens[0] == '.strn':
            self.assembleString(tokens, orgline, neg=True)
        elif tokens[0] == '.strp':
            self.assemblePackedString(tokens, orgline)
        elif tokens[0] in ('.longstring', '.compstring'):
            self.compstring = tokens[0] == '.compstring'
            if self.longstring is not None:
                self.fail(".longstring inside another .longstring.")
            if self.passnum == self.PSN_ASSEMBLY:
                self.logasm(None, msg='', orgline=orgline)
            self.longstring = []
            if len(tokens) > 1:
                self.assemblePackedString(tokens, orgline)
            # The address won't be incremented yet.
            self.incaddr(-1)
        elif tokens[0] == '.endstring':
            if self.compstring:
                self.assembleCompString(tokens, orgline)
            else:
                self.assembleLongString(tokens, orgline)
        elif tokens[0] == '.fill':
            self.assembleFill(tokens, orgline)
        elif tokens[0] == '.regfill':
            self.assembleFill(tokens, orgline, poketype='R')
        elif tokens[0] == '.page':
            self.assemblePage(tokens, orgline)
        elif tokens[0] == '.bank':
            self.assembleBank(tokens, orgline)
        elif tokens[0].startswith('.'):
            self.fail("Unknown assembler directive '%s'." % tokens[0])


    def assembleString(self, tokens, orgline, neg=False):
        """Assemble a string directive.

        A string directive places each value specified as a token in
        memory. Values can be strings enclosed in double-quotes or symbols,
        e.g.:

        .str "Hello, world!" 0   ; A null-terminated string.
        """
        if self.passnum == self.PSN_ASSEMBLY:
            self.logasm(None, msg='', orgline=orgline)
            #print 'A: %04x:      ; %s' % (self.addr, orgline)

        tokens = tokens[1:]
        for i, token in enumerate(tokens):
            if token.startswith('"'):
                # The lexer guarantees strings are enclosed in double
                # quotes. Strip them.
                chars = token[1:-1]
            else:
                # If it's not a string token, it should parse to an integer of sorts.
                chars = [self.parseToken(token)]

            for j, char in enumerate(chars):
                # Convert it to an int. Try numerous things.
                if type(char) == bytes:
                    val = ord(char)
                elif type(char) == str:
                    val = ord(char)
                elif type(char) == int:
                    val = char
                    char = chr(val)
                elif isinstance(char, Symbol):
                    val = char.assembly_val
                    char = chr(val)
                else:
                    self.fail('string/data element has weird type %s' % type(char))
                    
                if self.passnum == self.PSN_ASSEMBLY:
                    char = isprint(char) and char or ' '

                    # If this is the last character of the last token, and
                    # we're storing negative-terminated strings, OR the value
                    # with 0x8000.
                    if neg and ((i + 1) == len(tokens)) and ((j + 1) == len(chars)):
                        val |= 0x8000
                        self.logasm(val, orgline='"%s" (U+%04x) | 0x8000' % (char, val))
                    else:
                        self.logasm(val, orgline='"%s" (U+%04x)' % (char, val))

                self.poke(val, poketype='S')
                self.incaddr()

        # Our caller will increment the address, so adjust here.
        self.incaddr(-1)


    def assembleLongString(self, tokens, orgline):
        """Assemble the previously gathered tokens of a long string."""
        if self.longstring is None:
            self.fail(".endstring without matching .longstring!")
            return

        tokens = [ '.strp' ] + self.longstring + ['0']
        #print "*** TOKENS:", tokens
        self.longstring = None
        self.assemblePackedString(tokens, orgline)


    def assembleCompString(self, tokens, orgline, null=True):
        """Assemble a run-length, VDU-style packed string (.compstring
        directive).

        A compressed string stores byte values, one byte per word,
        with an off-by-one repetition count in the high-order
        bits. For instance, a value of &0041 decompresses to 'A'. A
        value of &0242 decompresses to 'CCC'. The repetition count is
        purposefully compatible to the VDU's CRR register.

        The string is null-terminated with a word value &0000 unless
        the optional argument null=False is provided.
        """
        raise RuntimeError('Not fully implemented yet')
        print(tokens)
        if self.passnum == self.PSN_ASSEMBLY:
            self.logasm(None, msg='', orgline=orgline)
            #print 'A: %04x:      ; %s' % (self.addr, orgline)

        tokens = tokens[1:]
        state = (0, None)

        def _storeChar(byteVal, state):
            if state[1] == byteVal and state[1] <= 256:
                state = (state[0] + 1, state[1])
            else:
                if state[1] is not None:
                    if self.passnum == self.PSN_ASSEMBLY:
                        val = ((state[0] - 1) << 8) | (state[1] & 0xff)
                        if state[0] < 40 and isprint(chr(state[1])):
                            s = '"%s"' % (chr(state[1]) * state[0])
                        else:
                            s = '"."'
                        self.logasm(val, orgline='%s %(U+%04x) x %d' % (s, state[1], state[0]))
                    self.poke(val, poketype='C')
                    self.incaddr()
                state = (1, byteVal)

            return state

        for i, token in enumerate(tokens):
            print(i, token)
            if token.startswith('"'):
                # The lexer guarantees strings are enclosed in double
                # quotes. Strip them.
                chars = token[1:-1]
            else:
                # If it's not a string token, it should parse to an integer of sorts.
                chars = [self.parseToken(token)]

            for j, char in enumerate(chars):
                try:
                    val = ord(char)
                except TypeError:
                    # It's already an int.
                    val = char
                state = _storeChar(val, state)

        if null:
            _storeChar(0, state)
        # Our caller will increment the address, so adjust here.
        self.incaddr(-1)

    def assemblePackedString(self, tokens, orgline):
        """Assemble a packed null-terminated string directive.

        A packed string is a string in which 8-bit bytes are
        word-packed. Even characters of a string (including the first
        one) use the least significant 8 bits of a word. Odd
        characters use the most significant 8 bits.

        The string is terminated by the bit sequence 00000000. The
        user is responsible for including this! Use something like:

        .strp "Spam, spam, spam and spam." 0

        where the last '0' is the string terminator.

        Packed strings can contain any byte-encoded character set
        (including Unicode, encoded in UTF-8 or UTF-7). Even-sized
        strings need an extra word for their terminating null.
        """
        if self.passnum == self.PSN_ASSEMBLY:
            self.logasm(None, msg='', orgline=orgline)
            #print 'A: %04x:      ; %s' % (self.addr, orgline)

        def _storechar(wordval):
            if self.passnum == self.PSN_ASSEMBLY:
                if wordval & 0x80:
                    self.logasm(wordval, orgline='"%s" (U+%04x) | 0x80' % \
                                    (chr(wordval & 0x7f), wordval & 0x7f))
                elif wordval & 0x8000:
                    self.logasm(wordval, orgline='"%s%s" (U+%04x U+%04x) | 0x8000' % \
                                    (chr(wordval & 0x7f), chr((wordval & 0x7f00) >> 8),
                                     wordval & 0x7f, (wordval & 0x7f00) >> 8))
                else:
                    self.logasm(wordval, orgline='"%s%s" (U+%04x U+%04x)' % \
                                    (chr(wordval & 0x7f), chr((wordval & 0x7f00) >> 8),
                                     wordval & 0x7f, (wordval & 0x7f00) >> 8))

            self.poke(wordval, poketype='s')
            self.incaddr()

        tokens = tokens[1:]
        numchars = 0
        wordval = 0
        #pprint.pprint(tokens)
        for i, token in enumerate(tokens):
            #if len(tokens) > 1:
            #    print "\t***", i, token.replace('\n', r'\n')

            # If we're in longstring mode, just gather all the tokens
            # for later processing.
            if self.longstring is not None:
                self.longstring.append(token)
                continue

            if token.startswith('"'):
                # The lexer guarantees strings are enclosed in double
                # quotes. Strip them.
                chars = token[1:-1]
            else:
                # If it's not a string token, it should parse to an integer of sorts.
                chars = [self.parseToken(token)]

            for j, char in enumerate(chars):
                try:
                    val = ord(char)
                except TypeError:
                    # It's already an int.
                    val = char
                    char = chr(char)
                    #if ord(char) not in xrange(128):
                    #    self.fail("Packed strings can only contain 7-bit characters.")
                if self.passnum == self.PSN_ASSEMBLY:
                    char = isprint(char) and char or ' '

                    # If this is the last character of the last token, set the
                    # high bit.
                    #if ((i + 1) == len(tokens)) and ((j + 1) == len(chars)):
                    #    val |= 0x80

                if (numchars & 1) == 0:
                    wordval = val
                else:
                    wordval = wordval | (val << 8)
                    _storechar(wordval)
                numchars += 1

        # There may be a leftover character when we're done.
        if (numchars & 1) != 0: # Note, numchars already increased: reverse semantics
            _storechar(val)

        # Our caller will increment the address, so adjust here.
        self.incaddr(-1)


    def assembleFill(self, tokens, orgline, poketype='F'):
        """Assemble a fill directive.

        Syntax: .fill COUNT WORD

        This will fill COUNT words starting at the current location with WORD,
        which can be any symbol that parses to a word (instruction, mnemonic,
        label, literal, etc).
        
        The COUNT must be a literal.
        """
        self.jumped = False
        try:
            count = self.parseInt(tokens[1])
        except Exception as e:
            self.fail(str(e))

        if self.passnum != self.PSN_ASSEMBLY:
            # We use count - 1 because the caller will increment the address
            # too.
            self.incaddr(count - 1)
            return
        
        # Assembly pass: do actual work.
        try:
            word = self.parseField(tokens[2:], allbits=True)
            try:
                word = word.val
            except AttributeError:
                pass
        except Exception as e:
            self.fail(str(e))

        self.logasm(None, msg=' .fill &%04x &%04x ; %s' % (count, word, orgline))

        for x in range(count):
            self.poke(word, poketype=poketype)
            self.incaddr()

        # Inhibit the next address increase.
        self.jumped = True


        
    def assemblePage(self, tokens, orgline):
        """Assemble a page directive.

        Syntax: .page [WORD]

        The .page directive automatically fills memory with WORD (which can be
        any parseable assembler expression, and defaults to zero) until the end
        of the current page is reached. This is useful for keeping code with
        relative addressing in the same memory area.

        Using .page allows code to run without rearranging during development.

        If more than 16 words are filled as a result of .page, a message is
        output during assembly. If more than 64 words are filled, a warning is
        output. If more than 128 words are filled, an error is raised.
        """
        self.jumped = False

        nextpage = (((self.addr >> 10) + 1) << 10)
        count = nextpage - self.addr

        # Already at the beginning of a page. Do nothing.
        if count == 0:
            return
        #elif count > 512:
        #    if self.passnum == self.PSN_ASSEMBLY:
        #        self.fail(".page generated %d words of slack space. Rearrange your code!" % count)
        elif count > 256:
            if self.passnum == self.PSN_ASSEMBLY:
                self.warn(".page generated %d words of slack space." % count)

        if self.passnum != self.PSN_ASSEMBLY:
            # We use count - 1 because the caller will increment the address
            # too.
            self.incaddr(count - 1)
            return
        
        # Assembly pass: do actual work.
        word = 0
        if len(tokens) >= 2:
            try:
                word = self.parseField(tokens[2:], allbits=True)
                try:
                    word = word.val
                except AttributeError:
                    pass
            except Exception as e:
                self.fail(str(e))

        self.logasm(None, msg=' .fill &%04x &%04x ; %s' % (count, word, orgline))

        for x in range(count):
            self.poke(word, poketype='P')
            self.incaddr()

        # Inhibit the next address increase.
        self.jumped = True


    def assembleBank(self, tokens, orgline):
        """Assemble a bank directive.

        Syntax: .bank BYTE

        The .bank directive sets the ROM bank being assembled to. The BYTE
        value, which must be from 0 to 255, sets the 8 high order bits of the
        address. This allows cftasm to assemble multi-bank code.
        """

        bank = self.parseField(tokens[2:], allbits=True)
        if bank < 0 or bank > 255:
            self.fail('bank should be in the range &00-&FF')
            
        self.bank = bank & 0xff
        # TODO: reinstate this after bank support is completed (and *if*)
        #self.pasm.write('\n\n.bank %02x\n\n' % self.bank)

        # Inhibit the next address increase.
        self.jumped = True


    def pushNamespace(self, line):
        """Enter a new namespace.

        Namespaces segregate symbols to avoid name polution and allow
        semi-private symbols to be defined.
        """
        try:
            name = re.findall('^\.pushns\s+(\w+)\s*', line)[0]
        except (TypeError, IndexError):
            self.fail('syntax error parsing .pushns')

        self.ns.append(name)


        
    def popNamespace(self, line):
        """Leave the last namespace.
        """
        try:
            assert re.findall('^(\.popns)\s*', line)[0] != ''
        except (TypeError, IndexError):
            self.fail('syntax error parsing .popns')

        if len(self.ns) == 0:
            self.fail('namespace/scope stack already empty!')

        self.ns = self.ns[:-1]


    def startScope(self, line):
        """Start a new scope.
        """
        self.scope += 1
        self.pushNamespace('.pushns _s%d' % self.scope)
    

    def endScope(self, line):
        """End the last scope.
        """
        self.popNamespace('.popns')
        # if len(self.scope) > 0:
        #     for sym in self.scope.pop():
        #         try:
        #             print "Deleting scope-local symbol %s" % sym
        #             del self.symbols[sym]
        #         except KeyError:
        #             continue
        # else:
        #     self.fail('.endscope without matching .scope.')
        
    def assembleInstruction(self, tokens, orgline):
        """Assemble a single instruction.

        The output is XORred with 0x400, the R flag, which is active LOW in the
        machine. This is to simplify assembly by ORring values (obviously: you
        can't turn 1 into 0 through OR).
        """
        self.jumped = False
        # Only assemble if we're on the assembly pass.
        if self.passnum == self.PSN_ASSEMBLY:
            # This will raise appropriate exceptions.

            # Alexios (2012-01-23) the R flag has reversed semantics in
            # microcode version 4, so we no longer need to toggle it. Code will
            # work as expected now.
            val = self.parseField(tokens) # ^ self.R_FLAG
            self.poke(val, poketype='I')
            self.logasm(val, orgline=orgline)


    def lexer(self, line):
        r"""Tokenise a line.

        >>> x = CFTAssembler()
        >>> list(x.lexer('foo bar'))
        ['foo', 'bar']
        >>> list(x.lexer('foo bar "baz"'))
        ['foo', 'bar', '"baz"']
        >>> list(x.lexer('foo bar "baz;\\n" ; a test'))
        ['foo', 'bar', '"baz;\n"']
        """
        buf = list()
        inquote = False
        esc = False
        for char in line.strip():
            if not inquote:
                if char == '"':
                    if buf:
                        yield str(''.join(buf))
                    inquote = True
                    buf = [char]
                    continue
                elif char in ';/':
                    if buf:
                        yield str(''.join(buf))
                    buf = list()
                    break
                elif char in ':[]()':
                    if buf:
                        yield str(''.join(buf))
                    yield char
                    buf = list()
                    continue
                elif char in "\t ":
                    if buf:
                        yield str(''.join(buf))
                    buf = list()
                    continue
                else:
                    buf.append(char)

            if inquote:
                if not esc:
                    if char == '\\':
                        esc = True
                        continue
                    elif char == '"':
                        buf.append(char)
                        inquote = False
                        yield str(''.join(buf))
                        buf = list()
                        continue
                    else:
                        buf.append(char)
                else:
                    if char == 'n':
                        buf.append('\n')
                    elif char == 't':
                        buf.append('\t')
                    elif char == 'b':
                        buf.append('\b')
                    elif char == '\\':
                        buf.append('\\')
                    elif char == '"':
                        buf.append('"')
                    esc = False

        if buf:
            yield str(''.join(buf))

        
    def parseToken(self, x, pageboundary=True):
        """Parse a lexical token, be it literal or symbolic.

        >>> x = CFTAssembler()
        >>> x.addSymbol('spam', 42)
        >>> x.addSymbol('eggs', 65535)
        >>> x.parseToken('spam')
        42
        >>> x.parseToken('eggs')
        65535
        >>> x.parseToken('&1000')
        4096
        >>> x.parseToken('#1000')
        1000
        >>> x.parseToken(':1000')
        8
        >>> x.addr = 32
        >>> x.parseToken('@-10')
        22
        >>> x.parseToken('@-&10')
        16
        >>> x.parseToken('@+&10')
        48
        """
        # Is it a bracket-like convenience symbol? Note that, just like the
        # PAL-8 assembler, we do NOT check for balanced parentheses!
        #if x in '()':
        #    return self.R_FLAG
        #elif x in '[]':
        #    return self.I_FLAG
            
        # Is it in the symbol table?
        try:
            return self.getSymbol(x)
        except KeyError:
            if re.match('^[A-Za-z]', x):
                #print "Failed to look up", x
                # An undefined symbol was used during the macro or symbol
                # discovery passes. Defer this symbol for another pass.
                #if x not in self.deferred:
                #    self.deferred.append(x)
                #    print "Pass %d: deferring resolution of symbol '%s'" % (self.passnum, x)
                if self.passnum == self.PSN_ASSEMBLY:
                    self.fail("Unknown symbol '%s'." % x)
                return 0xdead

            try:
                # Does it start with a '@'? If so, check relative
                # references, making sure they reference an address on
                # the same page as the current one.
                if x == '@':
                    return self.addr
                elif x.startswith('@-'):
                    addr = (self.addr - self.parseInt(x[2:])) & 0xffff
                    if pageboundary:
                        if (addr & 0xfc00) != (self.addr & 0xfc00):
                            self.fail("relative reference '%s' (%04x) crosses page boundary." % (x, addr))
                    return addr
                elif x.startswith('@+'):
                    addr = (self.addr + self.parseInt(x[2:])) & 0xffff
                    if pageboundary:
                        if (addr & 0xfc00) != (self.addr & 0xfc00):
                            self.fail("relative reference '%s' (%04x) crosses page boundary." % (x, addr))
                    return addr
                elif x.startswith('@'):
                    # Attempt to parse @<token><op><token> syntax.
                    try:
                        left, op, right = re.findall('^@(.+?)([+*/&|^-]|<<|>>)(.+)$', x)[0]
                        left = self.parseToken(left)
                        right = self.parseToken(right)
                    except IndexError:
                        self.fail("unable to parse relative address '%s'." % x)

                    try:
                        left = left.val
                    except AttributeError:
                        pass
                    try:
                        right = right.val
                    except AttributeError:
                        pass
                    
                    try:
                        val = {
                            '+': lambda a, b: a + b,
                            '-': lambda a, b: a - b,
                            '|': lambda a, b: a | b,
                            '&': lambda a, b: a & b,
                            '*': lambda a, b: a * b,
                            '/': lambda a, b: a // b,
                            '^': lambda a, b: a ^ b,
                            '<<': lambda a, b: a << b,
                            '>>': lambda a, b: a >> b,
                            }[op](left, right) & 0xffff
                        
                        val = eval('%s %s %s' % (left, op, right)) & 0xffff
                    except:
                        self.fail("Failed to parse relative expression '%s'." % x)
                    #self.fail("TEST: (%s) (%s) (%s) => %d" % (left, op, right, val))
                    return val
                else:
                    return self.parseInt(x)
            except ValueError:
                self.fail("unable to parse literal value '%s'." % x)


    def parseField(self, tokens, allbits=False, pageboundary=True):
        """Parse a whole field of tokens.

        Works by parsing each token into an integer, and ORring all integers
        together.

        >>> x = CFTAssembler()
        >>> x.addSymbol('spam', 0xef)
        >>> x.addSymbol('eggs', 0xbe00)
        >>> hex(x.parseField('spam eggs'))
        '0xbeef'
        >>> hex(x.parseField('eggs :101'))
        '0xbe05'
        >>> hex(x.parseField('&be00 #4 :1'))
        '0xbe05'
        >>> hex(x.parseField('foo'))
        Traceback (most recent call last):
        ValueError: unable to parse literal 'foo'
        """
        if hasattr(tokens, 'split'):
            tokens = tokens.split()
        res = 0
        for token in tokens:
            val = self.parseToken(token, pageboundary=pageboundary)
            if val is None:
                return None
            try:
                #res |= val
                if allbits:
                    res |= val
                else:
                    res |= (val & 0x03ff)

            except TypeError:
                if allbits:
                    res |= val.val

                else:
                    # Check if the symbol referenced is accessible
                    relto = self.addr & 0xfc00
                    if res & self.R_FLAG:
                        relto = 0
                    if val.inaccessible(relto):
                        self.warn("%s '%s' on page %04x, but page %04x accessed instead." %
                                  (val.__class__.__name__, token,
                                   val.page, relto))
                    res |= val.assembly_val
        return res


    def outmap(self):
        """Print out the map file."""
        # Open the map output file.
        out = open(self.map_file, 'w')

        def mapcmp(a,b):
            return cmp(a.val, b.val) or cmp(a.filename, b.filename) or \
                cmp(a.linenum, b.linenum) or cmp(a.name, b.name)

        labels = [ x for x in list(self.symbols.values()) if isinstance(x, Label) ]
        if not labels:
            out.write('nothing  0000  <none>:0')
            return

        fmt = '%%-%ds  %%04x  %%s:%%d\n' % max(len(x.name) for x in labels)

        for sym in sorted(labels, key=lambda x: (x.val, x.filename, x.linenum, x.name)):
            out.write(fmt % (sym.name, sym.val, sym.filename, sym.linenum))

        # Close it, just in case.
        out.close()
            

    def outxpm(self):
        """Print out the xpm map file."""
        # Open the map output file.
        if not self.opts.xpm:
            return

        out = open(self.xpm_map_file, 'w')
        out.write(XPMHEAD)

        for ofs in range(0, 65536, 256):
            out.write(',\n"%s"' % ''.join(chr(self.sentinel[ofs:ofs+256])))

        out.write(XPMFOOT)

        # Close it, just in case.
        out.close()
            

    def getSymbol(self, sym):
        """Return the value of a symbol from the symbol table. Raise KeyError
        if it doesn't exist."""

        if re.match('^[@#&0-9]', sym):
            raise KeyError

        #print "Looking up", sym
        if re.match('^[^a-zA-Z_]', sym):
            raise KeyError             # It's a literal, not a symbol

        for x in range(len(self.ns), -1, -1):
            try:
                nssym = '.'.join(self.ns[0:x] + [sym])
                #print "Pass", self.passnum, ", Looking up", nssym, self.ns
                return self.symbols[nssym]
            except KeyError:
                continue
        # Failed to find it.
        raise KeyError
            

    def getMacro(self, name):
        """Return the value of a macro from the macro table. Raise KeyError
        if it doesn't exist."""

        #print "Looking up macro", name
        for x in range(len(self.ns), -1, -1):
            try:
                nsname = '.'.join(self.ns[0:x] + [name])
                #print "Pass", self.passnum, ", Looking up", nsname, self.ns
                return self.macros[nsname]
            except KeyError:
                continue
        # Failed to find it.
        raise KeyError
            

    def addSymbol(self, sym, val, symtype=None):
        """Add a symbol to the symbol table.

        >>> x = CFTAssembler()
        >>> x.addSymbol('spam', 42)
        >>> x.addSymbol('spam', 43)
        <none>:1:warning: redefining symbol spam (#42) to different value (#43).
        """
        # Prefix the symbol with all namespaces
        sym0 = sym
        sym = '.'.join(self.ns + [sym])
        
        # Add local symbols to the current scope, if necessary
        #if sym0.startswith('_') and len(self.scope) > 0:
        #    self.scope[-1].append(sym)

        #print "File", self.filename, "Pass", self.passnum, ", adding symbol", sym

        # TODO: issue a warning if redefining a symbol.
        if sym in self.symbols:
            old = self.symbols[sym]
            if val != old.val and self.passnum == self.PSN_SYMBOL_DISCOVERY \
                    and (old.filename, old.linenum) != (self.filename, self.linenum):
                self.warn('redefining symbol %s (#%d) to different value (#%d).' % \
                              (sym, old.val, val))
                self.warn('previous declaration of %s in file %s line %d.' % \
                              (sym, old.filename, old.linenum))
        cls = symtype or Symbol
        if self.opts.debugging:
            sys.stderr.write('D: %s:%d: %04x addSymbol %s = %d, type=%s\n' % \
                                 (self.filename, self.linenum, self.addr, sym, val, str(cls)))
        self.symbols[sym] = cls(sym, val, self.filename, self.linenum)

        
    def mkaddr21(self, addr):
        """Make a full 21-bit physical address based on the current bank and an
        address, or return just the address."""
        if self.opts.banked:
            return ((self.bank << 13) + (addr & 0x1fff)) & 0x1fffff
        return addr & 0xffff


    def mkaddr24(self, addr):
        """Make a full 24-bit physical address based on the current bank and an
        address, or return just the address."""
        if self.opts.banked:
            return (((self.bank & 0xff) << 16) + (addr & 0xffff)) & 0xffffff
        return addr & 0xffff


    def poke(self, val, addr=None, poketype="?"):
        """Store an address in the memory image. The optional address may be
        used to override the current address."""
        self.jumped = False
        addr = addr or self.addr

        if poketype not in 'R' and self.opts.banked and self.bank is None:
            self.fail("assembling code before setting a bank (use .bank XX).")

        # Sanity check.
        if poketype == 'I':
            if (addr < self.opts.min_addr) and not self.boundwarn_low:
                self.boundwarn_low = True
                self.warn('Assembling code at address %06x, object file contains %06x-%06x' % \
                              (addr, self.opts.min_addr, self.opts.max_addr))
            elif (addr > self.opts.max_addr) and not self.boundwarn_high:
                self.boundwarn_high = True
                self.warn('Assembling code at address %06x, object file contains %06x-%06x' % \
                              (addr, self.opts.min_addr, self.opts.max_addr))

        self.minaddr = min(self.minaddr, self.addr)
        self.maxaddr = max(self.maxaddr, self.addr)

        try:
            poketype = chr(poketype)
        except:
            pass

        #if self.passnum == self.PSN_ASSEMBLY:
        #    if self.sentinel[addr] != '\0':
        #        datatype = {
        #            'I': 'instruction',
        #            'W': '.word',
        #            'S': 'string',
        #            'F': '.fill',
        #            }.get(self.sentinel[addr], '(unknown type)')
        #        self.warn('Code at address %04x overrides previous %s data.' %
        #                  (addr, datatype))

        self.mem[self.mkaddr24(addr or self.addr)] = val & 0xffff
        self.sentinel[self.mkaddr24(addr)] = ord(poketype)


    def yieldmem(self):
        """Yield each word of memory (in the range specified on the
        command line) as an (addr, data) tuple."""
        a0 = self.opts.min_addr
        a1 = self.opts.max_addr + 1
        for addr in range(a0, a1):
            yield (addr, self.mem[self.mkaddr24(addr)])


    def outobj(self):
        """Write object code."""
        a0 = self.opts.min_addr
        a1 = self.opts.max_addr + 1
        self.mem[a0:a1].tofile(open(self.opts.out_file, 'wb'))

        # In this version, we always output Verilog files.
        if True or self.opts.verilog:
            # Also write two Verilog ROM images (low and high half-words)
            basename = os.path.splitext(self.opts.out_file)[0]
            lo = open('%s-00.list' % basename, 'wt')
            hi = open('%s-01.list' % basename, 'wt')
            if self.opts.verbose:
                for addr, val in self.yieldmem():
                    lo.write("%s\t// %04x: %04x\n" % (bin(val & 0xff)[2:].zfill(8), addr, val))
                    hi.write("%s\t// %04x: %04x\n" % (bin((val >> 8) & 0xff)[2:].zfill(8), addr, val))
            else:
                for addr, val in self.yieldmem():
                    lo.write(bin(val & 0xff)[2:].zfill(8) + '\n')
                    hi.write(bin((val >> 8) & 0xff)[2:].zfill(8) + '\n')

            lo.close()
            hi.close()


    def logasm(self, val, msg=None, orgline=None):
        """Logs an assembly message.

        Assembly messages log the entire program
        in a format that is human-readable but may be parsed by both the
        assembler and other machine tools.

        If val is None, then no machine-code value is dumped for this
        line. This is used to log multi-word directives etc.
        """
        if val is not None and msg is not None:
            raise ValueError('Exactly one of val, msg may be set.')

        msg = msg or ''
        if orgline:
            orgline = ' ; ' + orgline
        else:
            orgline = ''

        if self.opts.banked:
            fmt = "&{:>06x}:"
        else:
            fmt = "&{:>04x}:"
            
        if val is None:
            line = (fmt + "      {}{}\n").format(self.addr, msg, orgline)
        else:
            line = (fmt + " &{:>04x}{}\n").format(self.addr, val, orgline)
        if self.opts.verbose:
            sys.stdout.write(line)
        self.pasm.write(line)


if __name__ == "__main__":
    CFTAssembler().run()

# End of file.
